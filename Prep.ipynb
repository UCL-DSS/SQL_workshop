{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL workshop prep\n",
    "\n",
    "This notebook is used to be able to load the data into the SQL server that we have crteaed using docker. This simplifies some of the data upload that would otherwise be a bit more complicated in SQL. If you want to do this manually, then more information can be found [here](https://towardsdatascience.com/how-to-import-a-csv-file-into-mysql-workbench-17cb120169c8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\phili\\anaconda3\\envs\\urbansim\\lib\\site-packages (1.4.19)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\phili\\anaconda3\\envs\\urbansim\\lib\\site-packages (from sqlalchemy) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "#first install teh necessary libarires\n",
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, types\n",
    "from sqlalchemy import Integer, Date, String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['double.csv', 'single.csv']\n"
     ]
    }
   ],
   "source": [
    "#get a list of all the files in the data file\n",
    "from os import listdir\n",
    "\n",
    "files = [f for f in listdir(\"Data/\")]\n",
    "\n",
    "#check that the files exist where you expect them to be\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107384 entries, 0 to 107383\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   Show Number  107384 non-null  int64         \n",
      " 1   Air Date     107384 non-null  datetime64[ns]\n",
      " 2   Category     107384 non-null  object        \n",
      " 3   Value        107384 non-null  int64         \n",
      " 4   Question     107384 non-null  object        \n",
      " 5   Answer       107383 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#read in the single file and make sure we get the information we expect\n",
    "single = pd.read_csv(\"Data/single.csv\", parse_dates = [1])\n",
    "single.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105912 entries, 0 to 105911\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   Show Number  105912 non-null  int64         \n",
      " 1   Air Date     105912 non-null  datetime64[ns]\n",
      " 2   Category     105912 non-null  object        \n",
      " 3   Value        105912 non-null  int64         \n",
      " 4   Question     105912 non-null  object        \n",
      " 5   Answer       105911 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#read in the double file and make sure it is correct\n",
    "double = pd.read_csv(\"Data/double.csv\", parse_dates = [1])\n",
    "double.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the engine to connect to the MYSQL database\n",
    "#information on this can be found here \n",
    "#https://www.calculatedata.com/connecting-to-mysql-database-in-python-using-sqlalchemy/\n",
    "engine = create_engine(\"mysql://root:UCL_DSS@localhost:3310/UCL_DSS_db?charset=utf8\")\n",
    "\n",
    "#we can then upload the dataframes to sql using the engine created\n",
    "double.to_sql('double_table',con=engine,index=True,if_exists='replace')\n",
    "single.to_sql('single_table',con=engine,index=True,if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbansim2",
   "language": "python",
   "name": "urbansim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
